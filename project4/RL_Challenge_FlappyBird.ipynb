{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_Challenge_FlappyBird.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QabXdcmgqmwD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh3986/kaggle/blob/main/project4/RL_Challenge_FlappyBird.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reinforcement Learning Challenge : FlappyBird"
      ],
      "metadata": {
        "id": "TUVhKt2Z4Lzh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l3n1FquB4DM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428fe3a0-0ac6-4724-94fa-48a6c3a49bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch) (1.15.0)\n",
            "Installing collected packages: pygame, munch\n",
            "Successfully installed munch-2.5.0 pygame-2.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pygame munch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive 연동\n",
        "구글 드라이브에 본 프로젝트 폴더를 저장한 후, 구글드라이브를 마운트\n"
      ],
      "metadata": {
        "id": "di1_QoEB_tX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/Kaggle/project_4_RL/RL_Challenge')  # 본 프로젝트 폴더 주소를 입력"
      ],
      "metadata": {
        "id": "pu_JBQxX6l7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09413bbb-a67e-4e86-dde3-2d65b9a5eb83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Colab Notebooks/Kaggle/project_4_RL/RL_Challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlMwm9bZioMr",
        "outputId": "d1dd1f12-3ad0-4328-8bb0-7915bb1bd053"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/Kaggle/project_4_RL/RL_Challenge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*DQN* class 정의"
      ],
      "metadata": {
        "id": "5awNZMPKWwUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, channel_in=1):\n",
        "        super(DQN, self).__init__()\n",
        "        self.number_of_actions = 2\n",
        "\n",
        "        # 1, 1, 84, 84\n",
        "        self.conv1 = nn.Conv2d(channel_in, 32, kernel_size = 8, stride = 4)\n",
        "        # 1, 32, 20, 20\n",
        "        self.conv2 = nn.Conv2d(32, 64, 4, 2)\n",
        "        # 1, 64, 9, 9\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, 1)\n",
        "        # 1, 64, 7, 7\n",
        "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
        "        self.fc5 = nn.Linear(512, self.number_of_actions)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.fc4(x.view(x.size(0), -1)))\n",
        "        return self.fc5(x)\n"
      ],
      "metadata": {
        "id": "ECP1VSJTWvJb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "H9dnCn_CXUjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "from glob import glob\n",
        "from collections import deque\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "\n",
        "from game import Game\n",
        "from utils import init_weights\n",
        "from munch import Munch"
      ],
      "metadata": {
        "id": "t_YHp10bqCvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc68a5b-2ed2-43dc-e4c5-8349ac82ebfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.1.2 (SDL 2.0.16, Python 3.7.13)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "AFhd2GQzxWpp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    \"game\": \"flappy\",\n",
        "    \"gamma\": 0.99,\n",
        "    # \"epsilon\": 0.02,\n",
        "    \"initial_epsilon\": 0.1,\n",
        "    \"final_epsilon\":1e-4,\n",
        "    \"iteration\": 1000000,\n",
        "    \"lr\": 1e-4,\n",
        "    \"use_pretrained\": False,\n",
        "    \"tag\": \"dqn\",\n",
        "    \"writer\": \"writer\",\n",
        "    \"batch_size\" : 32,\n",
        "    \"memory_size\":5000\n",
        "}\n",
        "args = Munch(args)\n",
        "\n",
        "args.writer = SummaryWriter(os.path.join('ckpt', args.tag))\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "print('GPU Enabled: {}'.format(torch.cuda.is_available()))"
      ],
      "metadata": {
        "id": "OI-JJA4cq5rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d9ecd3-9fcf-4cbf-99b9-5dc627c3ffe2"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Enabled: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import random\n",
        "\n",
        "class ReplayBuffer():\n",
        "    def __init__(self):\n",
        "        self.buffer = collections.deque(maxlen=args.memory_size)\n",
        "\n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "    \n",
        "    def sample(self):\n",
        "        mini_batch = random.sample(self.buffer,  min(len(self.buffer), args.batch_size))\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            s, a, r, s_prime, done = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append(a)\n",
        "            r_lst.append(r)\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_lst.append(done)\n",
        "\n",
        "        return torch.cat(tuple(s for s in s_lst)), \\\n",
        "                torch.cat(tuple(a for a in a_lst)), \\\n",
        "                torch.cat(tuple(r for r in r_lst)), \\\n",
        "                torch.cat(tuple(s_prime for s_prime in s_prime_lst)), \\\n",
        "                torch.cat(tuple(done for done in done_lst))\n",
        "\n",
        "    def flush(self, size=1):\n",
        "        for _ in range(size):\n",
        "            self.buffer.popleft()\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "    \n",
        "    def isfull(self):\n",
        "        return len(self.buffer) == args.memory_size"
      ],
      "metadata": {
        "id": "zuNpgahS0HEk"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DQN()\n",
        "model_target = DQN()\n",
        "\n",
        "if args.use_pretrained:\n",
        "    model = torch.load(\n",
        "        sorted(glob(os.path.join('ckpt', args.tag, '*.pth')))[-1]\n",
        "    )\n",
        "else:\n",
        "    os.makedirs(os.path.join('ckpt', args.tag), exist_ok = True)\n",
        "    model.apply(init_weights)\n",
        "model = model.cuda()\n",
        "start = time.time()\n",
        "\n",
        "episode = 0\n",
        "iteration = 0\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "# instantiate game\n",
        "game = Game(game=args.game)\n",
        "high_total_reward = 0"
      ],
      "metadata": {
        "id": "3TnqSBXeqzXN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize replay memory\n",
        "memory = ReplayBuffer()\n",
        "\n",
        "elapsed_time = 0\n",
        "action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "total_reward = game.reward\n",
        "terminal = game.game_over()\n",
        "\n",
        "image_data = game.get_torch_image().cuda()\n",
        "state = image_data.unsqueeze(0)\n",
        "\n",
        "start = time.time()"
      ],
      "metadata": {
        "id": "LD3rMU258pGs"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while iteration < args.iteration:\n",
        "    output = model(state)[0]\n",
        "    action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "    \n",
        "    # epsilon greedy exploration\n",
        "    # Pick action --> random or index of maximum q value\n",
        "    epsilon = args.final_epsilon + ((args.iteration - iteration) * (args.initial_epsilon - args.final_epsilon) / args.iteration)\n",
        "    coin = random.random()\n",
        "    random_action = coin <= epsilon\n",
        "    if random_action:\n",
        "        action_index =  random.randint(0, 1)\n",
        "    else:\n",
        "        action_index =  output.argmax().item()\n",
        "\n",
        "    # coin = random.random()\n",
        "    # action_index = 0\n",
        "    # if coin < epsilon:\n",
        "    #     action_index =  random.randint(0, 1)\n",
        "    # else:\n",
        "    #     action_index =  output.argmax().item()\n",
        "\n",
        "    action[action_index] = 1\n",
        "\n",
        "    elapsed_time = time.time() - start\n",
        "\n",
        "    # get next state and reward\n",
        "    reward = game.act(action_index)\n",
        "    terminal = game.game_over()\n",
        "    \n",
        "    image_data_1 = game.get_torch_image().cuda()\n",
        "    state_1 = image_data_1.unsqueeze(0)\n",
        "    action = action.unsqueeze(0).cuda()\n",
        "    reward = torch.from_numpy(np.array([reward], dtype=np.float32)).unsqueeze(0).cuda()\n",
        "    done = torch.from_numpy(np.array([0.0 if terminal else 1.0], dtype=np.float32)).unsqueeze(0).cuda()\n",
        "\n",
        "    # save transition to replay memory\n",
        "    memory.put((state, action, reward, state_1, done))\n",
        "    # if replay memory is full, remove the oldest transition\n",
        "    if memory.isfull():\n",
        "        memory.flush()\n",
        "\n",
        "    #### minibatch Train\n",
        "    # sample random minibatch\n",
        "    # if (terminal) & (memory.size() > 2000):\n",
        "    s_batch, a_batch, r_batch, s_prime_batch, done_batch = memory.sample()\n",
        "    s_batch = s_batch.cuda()\n",
        "    a_batch = a_batch.cuda()\n",
        "    r_batch = r_batch.cuda()\n",
        "    s_prime_batch = s_prime_batch.cuda()\n",
        "    done_batch = done_batch.cuda()\n",
        "\n",
        "    # get output for the next state\n",
        "    q_out = model(s_batch)\n",
        "    q_prime_out = model(s_prime_batch) # q target으로 하도록\n",
        "\n",
        "    y_hat = torch.cat(\n",
        "                    tuple(reward if terminal else reward + args.gamma * torch.max(prediction) \n",
        "                            for reward, done, prediction in zip(r_batch, done_batch, q_prime_out))\n",
        "                )\n",
        "    y_hat = y_hat.detach()\n",
        "    q_value = torch.sum(q_out * a_batch, dim=1)\n",
        "    \n",
        "    # calculate with target network\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(q_value, y_hat)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    state = state_1\n",
        "    iteration += 1\n",
        "    total_reward += game.reward\n",
        "\n",
        "    args.writer.add_scalar('Train/loss', loss, iteration)\n",
        "\n",
        "    if terminal:\n",
        "        args.writer.add_scalar('Episode/elapsed_time', elapsed_time, episode)\n",
        "        args.writer.add_scalar('Episode/episode', episode, episode)\n",
        "        args.writer.add_scalar('Episode/total_reward', total_reward, episode)\n",
        "        \n",
        "        game.reset_game()\n",
        "        episode += 1\n",
        "        start = time.time()\n",
        "        print('Episode {} (Iteration {}): Agent passed {} pipes!, Time: {:.3f} epsilon: {:.4f}'.format(episode, iteration, total_reward, elapsed_time, epsilon))\n",
        "        if total_reward > high_total_reward:\n",
        "            print('Weight Saved!')\n",
        "            high_total_reward = total_reward\n",
        "            torch.save(model,\n",
        "                        os.path.join('ckpt', args.tag, 'E{:07d}_S{:03d}.pth'.format(episode, int(total_reward)))\n",
        "                        )\n",
        "        total_reward = 0\n",
        "        # image_data = game.get_torch_image().cuda()\n",
        "        # state = image_data.unsqueeze(0)\n",
        "\n",
        "print(\"Saving final model\")\n",
        "torch.save(model,\n",
        "            os.path.join('ckpt', args.tag, 'E_{:07d}_S{:03d}.pth'.format(episode, int(high_total_reward)))\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tc2DIycBqwu1",
        "outputId": "335773b7-5d65-4339-de6c-1cbf2dca8f33"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1 (Iteration 37): Agent passed 0.0 pipes!, Time: 2.529 epsilon\" 0.1000\n",
            "Episode 2 (Iteration 74): Agent passed 0.0 pipes!, Time: 0.317 epsilon\" 0.1000\n",
            "Episode 3 (Iteration 111): Agent passed 0.0 pipes!, Time: 0.319 epsilon\" 0.1000\n",
            "Episode 4 (Iteration 148): Agent passed 0.0 pipes!, Time: 0.317 epsilon\" 0.1000\n",
            "Episode 5 (Iteration 185): Agent passed 0.0 pipes!, Time: 0.313 epsilon\" 0.1000\n",
            "Episode 6 (Iteration 222): Agent passed 0.0 pipes!, Time: 0.330 epsilon\" 0.1000\n",
            "Episode 7 (Iteration 259): Agent passed 0.0 pipes!, Time: 0.328 epsilon\" 0.1000\n",
            "Episode 8 (Iteration 336): Agent passed 2.0 pipes!, Time: 0.684 epsilon\" 0.1000\n",
            "Weight Saved!\n",
            "Episode 9 (Iteration 373): Agent passed 0.0 pipes!, Time: 0.354 epsilon\" 0.1000\n",
            "Episode 10 (Iteration 410): Agent passed 0.0 pipes!, Time: 0.338 epsilon\" 0.1000\n",
            "Episode 11 (Iteration 447): Agent passed 0.0 pipes!, Time: 0.353 epsilon\" 0.1000\n",
            "Episode 12 (Iteration 491): Agent passed 1.0 pipes!, Time: 0.402 epsilon\" 0.1000\n",
            "Episode 13 (Iteration 534): Agent passed 1.0 pipes!, Time: 0.414 epsilon\" 0.0999\n",
            "Episode 14 (Iteration 571): Agent passed 0.0 pipes!, Time: 0.343 epsilon\" 0.0999\n",
            "Episode 15 (Iteration 609): Agent passed 0.0 pipes!, Time: 0.346 epsilon\" 0.0999\n",
            "Episode 16 (Iteration 651): Agent passed 1.0 pipes!, Time: 0.389 epsilon\" 0.0999\n",
            "Episode 17 (Iteration 697): Agent passed 1.0 pipes!, Time: 0.423 epsilon\" 0.0999\n",
            "Episode 18 (Iteration 734): Agent passed 0.0 pipes!, Time: 0.339 epsilon\" 0.0999\n",
            "Episode 19 (Iteration 807): Agent passed 1.0 pipes!, Time: 0.692 epsilon\" 0.0999\n",
            "Episode 20 (Iteration 858): Agent passed 1.0 pipes!, Time: 0.488 epsilon\" 0.0999\n",
            "Episode 21 (Iteration 901): Agent passed 1.0 pipes!, Time: 0.401 epsilon\" 0.0999\n",
            "Episode 22 (Iteration 974): Agent passed 1.0 pipes!, Time: 0.729 epsilon\" 0.0999\n",
            "Episode 23 (Iteration 1013): Agent passed 0.0 pipes!, Time: 0.371 epsilon\" 0.0999\n",
            "Episode 24 (Iteration 1050): Agent passed 0.0 pipes!, Time: 0.360 epsilon\" 0.0999\n",
            "Episode 25 (Iteration 1096): Agent passed 1.0 pipes!, Time: 0.431 epsilon\" 0.0999\n",
            "Episode 26 (Iteration 1140): Agent passed 1.0 pipes!, Time: 0.389 epsilon\" 0.0999\n",
            "Episode 27 (Iteration 1213): Agent passed 1.0 pipes!, Time: 0.668 epsilon\" 0.0999\n",
            "Episode 28 (Iteration 1250): Agent passed 0.0 pipes!, Time: 0.340 epsilon\" 0.0999\n",
            "Episode 29 (Iteration 1297): Agent passed 1.0 pipes!, Time: 0.421 epsilon\" 0.0999\n",
            "Episode 30 (Iteration 1374): Agent passed 2.0 pipes!, Time: 0.692 epsilon\" 0.0999\n",
            "Episode 31 (Iteration 1411): Agent passed 0.0 pipes!, Time: 0.346 epsilon\" 0.0999\n",
            "Episode 32 (Iteration 1448): Agent passed 0.0 pipes!, Time: 0.319 epsilon\" 0.0999\n",
            "Episode 33 (Iteration 1485): Agent passed 0.0 pipes!, Time: 0.353 epsilon\" 0.0999\n",
            "Episode 34 (Iteration 1521): Agent passed 0.0 pipes!, Time: 0.341 epsilon\" 0.0998\n",
            "Episode 35 (Iteration 1562): Agent passed 1.0 pipes!, Time: 0.371 epsilon\" 0.0998\n",
            "Episode 36 (Iteration 1608): Agent passed 1.0 pipes!, Time: 0.435 epsilon\" 0.0998\n",
            "Episode 37 (Iteration 1645): Agent passed 0.0 pipes!, Time: 0.330 epsilon\" 0.0998\n",
            "Episode 38 (Iteration 1694): Agent passed 1.0 pipes!, Time: 0.431 epsilon\" 0.0998\n",
            "Episode 39 (Iteration 1731): Agent passed 0.0 pipes!, Time: 0.332 epsilon\" 0.0998\n",
            "Episode 40 (Iteration 1804): Agent passed 1.0 pipes!, Time: 0.647 epsilon\" 0.0998\n",
            "Episode 41 (Iteration 1841): Agent passed 0.0 pipes!, Time: 0.335 epsilon\" 0.0998\n",
            "Episode 42 (Iteration 1884): Agent passed 1.0 pipes!, Time: 0.397 epsilon\" 0.0998\n",
            "Episode 43 (Iteration 1957): Agent passed 1.0 pipes!, Time: 0.681 epsilon\" 0.0998\n",
            "Episode 44 (Iteration 1994): Agent passed 0.0 pipes!, Time: 0.335 epsilon\" 0.0998\n",
            "Episode 45 (Iteration 2031): Agent passed 0.0 pipes!, Time: 0.359 epsilon\" 0.0998\n",
            "Episode 46 (Iteration 2074): Agent passed 1.0 pipes!, Time: 0.420 epsilon\" 0.0998\n",
            "Episode 47 (Iteration 2111): Agent passed 0.0 pipes!, Time: 0.337 epsilon\" 0.0998\n",
            "Episode 48 (Iteration 2184): Agent passed 1.0 pipes!, Time: 0.678 epsilon\" 0.0998\n",
            "Episode 49 (Iteration 2225): Agent passed 1.0 pipes!, Time: 0.378 epsilon\" 0.0998\n",
            "Episode 50 (Iteration 2278): Agent passed 1.0 pipes!, Time: 0.496 epsilon\" 0.0998\n",
            "Episode 51 (Iteration 2351): Agent passed 1.0 pipes!, Time: 0.711 epsilon\" 0.0998\n",
            "Episode 52 (Iteration 2388): Agent passed 0.0 pipes!, Time: 0.360 epsilon\" 0.0998\n",
            "Episode 53 (Iteration 2436): Agent passed 1.0 pipes!, Time: 0.448 epsilon\" 0.0998\n",
            "Episode 54 (Iteration 2473): Agent passed 0.0 pipes!, Time: 0.348 epsilon\" 0.0998\n",
            "Episode 55 (Iteration 2508): Agent passed 0.0 pipes!, Time: 0.337 epsilon\" 0.0997\n",
            "Episode 56 (Iteration 2545): Agent passed 0.0 pipes!, Time: 0.344 epsilon\" 0.0997\n",
            "Episode 57 (Iteration 2582): Agent passed 0.0 pipes!, Time: 0.336 epsilon\" 0.0997\n",
            "Episode 58 (Iteration 2627): Agent passed 1.0 pipes!, Time: 0.398 epsilon\" 0.0997\n",
            "Episode 59 (Iteration 2664): Agent passed 0.0 pipes!, Time: 0.348 epsilon\" 0.0997\n",
            "Episode 60 (Iteration 2701): Agent passed 0.0 pipes!, Time: 0.325 epsilon\" 0.0997\n",
            "Episode 61 (Iteration 2774): Agent passed 1.0 pipes!, Time: 0.645 epsilon\" 0.0997\n",
            "Episode 62 (Iteration 2811): Agent passed 0.0 pipes!, Time: 0.333 epsilon\" 0.0997\n",
            "Episode 63 (Iteration 2856): Agent passed 1.0 pipes!, Time: 0.384 epsilon\" 0.0997\n",
            "Episode 64 (Iteration 2893): Agent passed 0.0 pipes!, Time: 0.332 epsilon\" 0.0997\n",
            "Episode 65 (Iteration 2930): Agent passed 0.0 pipes!, Time: 0.334 epsilon\" 0.0997\n",
            "Episode 66 (Iteration 3039): Agent passed 2.0 pipes!, Time: 0.984 epsilon\" 0.0997\n",
            "Episode 67 (Iteration 3076): Agent passed 0.0 pipes!, Time: 0.339 epsilon\" 0.0997\n",
            "Episode 68 (Iteration 3149): Agent passed 1.0 pipes!, Time: 0.654 epsilon\" 0.0997\n",
            "Episode 69 (Iteration 3193): Agent passed 1.0 pipes!, Time: 0.389 epsilon\" 0.0997\n",
            "Episode 70 (Iteration 3262): Agent passed 1.0 pipes!, Time: 0.609 epsilon\" 0.0997\n",
            "Episode 71 (Iteration 3315): Agent passed 1.0 pipes!, Time: 0.459 epsilon\" 0.0997\n",
            "Episode 72 (Iteration 3356): Agent passed 1.0 pipes!, Time: 0.384 epsilon\" 0.0997\n",
            "Episode 73 (Iteration 3393): Agent passed 0.0 pipes!, Time: 0.345 epsilon\" 0.0997\n",
            "Episode 74 (Iteration 3441): Agent passed 1.0 pipes!, Time: 0.433 epsilon\" 0.0997\n",
            "Episode 75 (Iteration 3478): Agent passed 0.0 pipes!, Time: 0.326 epsilon\" 0.0997\n",
            "Episode 76 (Iteration 3505): Agent passed 0.0 pipes!, Time: 0.232 epsilon\" 0.0996\n",
            "Episode 77 (Iteration 3592): Agent passed 2.0 pipes!, Time: 0.806 epsilon\" 0.0996\n",
            "Episode 78 (Iteration 3636): Agent passed 1.0 pipes!, Time: 0.545 epsilon\" 0.0996\n",
            "Episode 79 (Iteration 3688): Agent passed 1.0 pipes!, Time: 0.632 epsilon\" 0.0996\n",
            "Episode 80 (Iteration 3725): Agent passed 0.0 pipes!, Time: 0.338 epsilon\" 0.0996\n",
            "Episode 81 (Iteration 3798): Agent passed 1.0 pipes!, Time: 0.839 epsilon\" 0.0996\n",
            "Episode 82 (Iteration 3871): Agent passed 1.0 pipes!, Time: 0.666 epsilon\" 0.0996\n",
            "Episode 83 (Iteration 3908): Agent passed 0.0 pipes!, Time: 0.340 epsilon\" 0.0996\n",
            "Episode 84 (Iteration 3945): Agent passed 0.0 pipes!, Time: 0.355 epsilon\" 0.0996\n",
            "Episode 85 (Iteration 4018): Agent passed 1.0 pipes!, Time: 0.851 epsilon\" 0.0996\n",
            "Episode 86 (Iteration 4085): Agent passed 1.0 pipes!, Time: 1.071 epsilon\" 0.0996\n",
            "Episode 87 (Iteration 4158): Agent passed 1.0 pipes!, Time: 1.026 epsilon\" 0.0996\n",
            "Episode 88 (Iteration 4188): Agent passed 0.0 pipes!, Time: 0.351 epsilon\" 0.0996\n",
            "Episode 89 (Iteration 4261): Agent passed 1.0 pipes!, Time: 0.976 epsilon\" 0.0996\n",
            "Episode 90 (Iteration 4304): Agent passed 1.0 pipes!, Time: 0.395 epsilon\" 0.0996\n",
            "Episode 91 (Iteration 4341): Agent passed 0.0 pipes!, Time: 0.325 epsilon\" 0.0996\n",
            "Episode 92 (Iteration 4378): Agent passed 0.0 pipes!, Time: 0.351 epsilon\" 0.0996\n",
            "Episode 93 (Iteration 4415): Agent passed 0.0 pipes!, Time: 0.353 epsilon\" 0.0996\n",
            "Episode 94 (Iteration 4467): Agent passed 1.0 pipes!, Time: 0.468 epsilon\" 0.0996\n",
            "Episode 95 (Iteration 4504): Agent passed 0.0 pipes!, Time: 0.329 epsilon\" 0.0996\n",
            "Episode 96 (Iteration 4541): Agent passed 0.0 pipes!, Time: 0.345 epsilon\" 0.0995\n",
            "Episode 97 (Iteration 4578): Agent passed 0.0 pipes!, Time: 0.342 epsilon\" 0.0995\n",
            "Episode 98 (Iteration 4615): Agent passed 0.0 pipes!, Time: 0.348 epsilon\" 0.0995\n",
            "Episode 99 (Iteration 4652): Agent passed 0.0 pipes!, Time: 0.312 epsilon\" 0.0995\n",
            "Episode 100 (Iteration 4715): Agent passed 1.0 pipes!, Time: 0.584 epsilon\" 0.0995\n",
            "Episode 101 (Iteration 4752): Agent passed 0.0 pipes!, Time: 0.348 epsilon\" 0.0995\n",
            "Episode 102 (Iteration 4789): Agent passed 0.0 pipes!, Time: 0.346 epsilon\" 0.0995\n",
            "Episode 103 (Iteration 4862): Agent passed 1.0 pipes!, Time: 0.709 epsilon\" 0.0995\n",
            "Episode 104 (Iteration 4915): Agent passed 1.0 pipes!, Time: 0.492 epsilon\" 0.0995\n",
            "Episode 105 (Iteration 4952): Agent passed 0.0 pipes!, Time: 0.339 epsilon\" 0.0995\n",
            "Episode 106 (Iteration 4989): Agent passed 0.0 pipes!, Time: 0.330 epsilon\" 0.0995\n",
            "Episode 107 (Iteration 5033): Agent passed 1.0 pipes!, Time: 0.440 epsilon\" 0.0995\n",
            "Episode 108 (Iteration 5071): Agent passed 0.0 pipes!, Time: 0.359 epsilon\" 0.0995\n",
            "Episode 109 (Iteration 5152): Agent passed 2.0 pipes!, Time: 0.783 epsilon\" 0.0995\n",
            "Episode 110 (Iteration 5189): Agent passed 0.0 pipes!, Time: 0.333 epsilon\" 0.0995\n",
            "Episode 111 (Iteration 5240): Agent passed 1.0 pipes!, Time: 0.491 epsilon\" 0.0995\n",
            "Episode 112 (Iteration 5277): Agent passed 0.0 pipes!, Time: 0.341 epsilon\" 0.0995\n",
            "Episode 113 (Iteration 5322): Agent passed 1.0 pipes!, Time: 0.421 epsilon\" 0.0995\n",
            "Episode 114 (Iteration 5359): Agent passed 0.0 pipes!, Time: 0.345 epsilon\" 0.0995\n",
            "Episode 115 (Iteration 5432): Agent passed 1.0 pipes!, Time: 0.658 epsilon\" 0.0995\n",
            "Episode 116 (Iteration 5481): Agent passed 1.0 pipes!, Time: 0.455 epsilon\" 0.0995\n",
            "Episode 117 (Iteration 5590): Agent passed 2.0 pipes!, Time: 1.338 epsilon\" 0.0994\n",
            "Episode 118 (Iteration 5643): Agent passed 1.0 pipes!, Time: 0.474 epsilon\" 0.0994\n",
            "Episode 119 (Iteration 5680): Agent passed 0.0 pipes!, Time: 0.392 epsilon\" 0.0994\n",
            "Episode 120 (Iteration 5753): Agent passed 1.0 pipes!, Time: 0.960 epsilon\" 0.0994\n",
            "Episode 121 (Iteration 5862): Agent passed 2.0 pipes!, Time: 0.998 epsilon\" 0.0994\n",
            "Episode 122 (Iteration 5899): Agent passed 0.0 pipes!, Time: 0.331 epsilon\" 0.0994\n",
            "Episode 123 (Iteration 5936): Agent passed 0.0 pipes!, Time: 0.351 epsilon\" 0.0994\n",
            "Episode 124 (Iteration 5973): Agent passed 0.0 pipes!, Time: 0.322 epsilon\" 0.0994\n",
            "Episode 125 (Iteration 6046): Agent passed 1.0 pipes!, Time: 0.687 epsilon\" 0.0994\n",
            "Episode 126 (Iteration 6080): Agent passed 0.0 pipes!, Time: 0.353 epsilon\" 0.0994\n",
            "Episode 127 (Iteration 6117): Agent passed 0.0 pipes!, Time: 0.335 epsilon\" 0.0994\n",
            "Episode 128 (Iteration 6154): Agent passed 0.0 pipes!, Time: 0.339 epsilon\" 0.0994\n",
            "Episode 129 (Iteration 6191): Agent passed 0.0 pipes!, Time: 0.332 epsilon\" 0.0994\n",
            "Episode 130 (Iteration 6300): Agent passed 2.0 pipes!, Time: 1.047 epsilon\" 0.0994\n",
            "Episode 131 (Iteration 6337): Agent passed 0.0 pipes!, Time: 0.355 epsilon\" 0.0994\n",
            "Episode 132 (Iteration 6374): Agent passed 0.0 pipes!, Time: 0.348 epsilon\" 0.0994\n",
            "Episode 133 (Iteration 6447): Agent passed 1.0 pipes!, Time: 0.694 epsilon\" 0.0994\n",
            "Episode 134 (Iteration 6496): Agent passed 1.0 pipes!, Time: 0.455 epsilon\" 0.0994\n",
            "Episode 135 (Iteration 6547): Agent passed 1.0 pipes!, Time: 0.492 epsilon\" 0.0993\n",
            "Episode 136 (Iteration 6623): Agent passed 1.0 pipes!, Time: 0.711 epsilon\" 0.0993\n",
            "Episode 137 (Iteration 6696): Agent passed 1.0 pipes!, Time: 0.673 epsilon\" 0.0993\n",
            "Episode 138 (Iteration 6733): Agent passed 0.0 pipes!, Time: 0.342 epsilon\" 0.0993\n",
            "Episode 139 (Iteration 6770): Agent passed 0.0 pipes!, Time: 0.360 epsilon\" 0.0993\n",
            "Episode 140 (Iteration 6843): Agent passed 1.0 pipes!, Time: 0.673 epsilon\" 0.0993\n",
            "Episode 141 (Iteration 6880): Agent passed 0.0 pipes!, Time: 0.334 epsilon\" 0.0993\n",
            "Episode 142 (Iteration 6933): Agent passed 1.0 pipes!, Time: 0.467 epsilon\" 0.0993\n",
            "Episode 143 (Iteration 6970): Agent passed 0.0 pipes!, Time: 0.328 epsilon\" 0.0993\n",
            "Episode 144 (Iteration 7023): Agent passed 1.0 pipes!, Time: 0.498 epsilon\" 0.0993\n",
            "Episode 145 (Iteration 7060): Agent passed 0.0 pipes!, Time: 0.329 epsilon\" 0.0993\n",
            "Episode 146 (Iteration 7102): Agent passed 1.0 pipes!, Time: 0.374 epsilon\" 0.0993\n",
            "Episode 147 (Iteration 7139): Agent passed 0.0 pipes!, Time: 0.340 epsilon\" 0.0993\n",
            "Episode 148 (Iteration 7176): Agent passed 0.0 pipes!, Time: 0.336 epsilon\" 0.0993\n",
            "Episode 149 (Iteration 7213): Agent passed 0.0 pipes!, Time: 0.336 epsilon\" 0.0993\n",
            "Episode 150 (Iteration 7257): Agent passed 1.0 pipes!, Time: 0.423 epsilon\" 0.0993\n",
            "Episode 151 (Iteration 7342): Agent passed 2.0 pipes!, Time: 0.782 epsilon\" 0.0993\n",
            "Episode 152 (Iteration 7379): Agent passed 0.0 pipes!, Time: 0.326 epsilon\" 0.0993\n",
            "Episode 153 (Iteration 7416): Agent passed 0.0 pipes!, Time: 0.326 epsilon\" 0.0993\n",
            "Episode 154 (Iteration 7453): Agent passed 0.0 pipes!, Time: 0.338 epsilon\" 0.0993\n",
            "Episode 155 (Iteration 7522): Agent passed 1.0 pipes!, Time: 0.619 epsilon\" 0.0992\n",
            "Episode 156 (Iteration 7604): Agent passed 2.0 pipes!, Time: 0.740 epsilon\" 0.0992\n",
            "Episode 157 (Iteration 7683): Agent passed 2.0 pipes!, Time: 0.718 epsilon\" 0.0992\n",
            "Episode 158 (Iteration 7732): Agent passed 1.0 pipes!, Time: 0.446 epsilon\" 0.0992\n",
            "Episode 159 (Iteration 7808): Agent passed 1.0 pipes!, Time: 1.005 epsilon\" 0.0992\n",
            "Episode 160 (Iteration 7845): Agent passed 0.0 pipes!, Time: 0.496 epsilon\" 0.0992\n",
            "Episode 161 (Iteration 7882): Agent passed 0.0 pipes!, Time: 0.505 epsilon\" 0.0992\n",
            "Episode 162 (Iteration 7925): Agent passed 1.0 pipes!, Time: 0.593 epsilon\" 0.0992\n",
            "Episode 163 (Iteration 7977): Agent passed 1.0 pipes!, Time: 0.719 epsilon\" 0.0992\n",
            "Episode 164 (Iteration 8014): Agent passed 0.0 pipes!, Time: 0.348 epsilon\" 0.0992\n",
            "Episode 165 (Iteration 8051): Agent passed 0.0 pipes!, Time: 0.340 epsilon\" 0.0992\n",
            "Episode 166 (Iteration 8089): Agent passed 0.0 pipes!, Time: 0.366 epsilon\" 0.0992\n",
            "Episode 167 (Iteration 8132): Agent passed 1.0 pipes!, Time: 0.414 epsilon\" 0.0992\n",
            "Episode 168 (Iteration 8176): Agent passed 1.0 pipes!, Time: 0.403 epsilon\" 0.0992\n",
            "Episode 169 (Iteration 8223): Agent passed 1.0 pipes!, Time: 0.437 epsilon\" 0.0992\n",
            "Episode 170 (Iteration 8260): Agent passed 0.0 pipes!, Time: 0.345 epsilon\" 0.0992\n",
            "Episode 171 (Iteration 8369): Agent passed 2.0 pipes!, Time: 1.017 epsilon\" 0.0992\n",
            "Episode 172 (Iteration 8406): Agent passed 0.0 pipes!, Time: 0.340 epsilon\" 0.0992\n",
            "Episode 173 (Iteration 8456): Agent passed 1.0 pipes!, Time: 0.449 epsilon\" 0.0992\n",
            "Episode 174 (Iteration 8493): Agent passed 0.0 pipes!, Time: 0.335 epsilon\" 0.0992\n",
            "Episode 175 (Iteration 8530): Agent passed 0.0 pipes!, Time: 0.344 epsilon\" 0.0991\n",
            "Episode 176 (Iteration 8567): Agent passed 0.0 pipes!, Time: 0.333 epsilon\" 0.0991\n",
            "Episode 177 (Iteration 8604): Agent passed 0.0 pipes!, Time: 0.327 epsilon\" 0.0991\n",
            "Episode 178 (Iteration 8641): Agent passed 0.0 pipes!, Time: 0.343 epsilon\" 0.0991\n",
            "Episode 179 (Iteration 8678): Agent passed 0.0 pipes!, Time: 0.326 epsilon\" 0.0991\n",
            "Episode 180 (Iteration 8713): Agent passed 0.0 pipes!, Time: 0.305 epsilon\" 0.0991\n",
            "Episode 181 (Iteration 8750): Agent passed 0.0 pipes!, Time: 0.343 epsilon\" 0.0991\n",
            "Episode 182 (Iteration 8787): Agent passed 0.0 pipes!, Time: 0.339 epsilon\" 0.0991\n",
            "Episode 183 (Iteration 8835): Agent passed 1.0 pipes!, Time: 0.413 epsilon\" 0.0991\n",
            "Episode 184 (Iteration 8888): Agent passed 1.0 pipes!, Time: 0.476 epsilon\" 0.0991\n",
            "Episode 185 (Iteration 8925): Agent passed 0.0 pipes!, Time: 0.319 epsilon\" 0.0991\n",
            "Episode 186 (Iteration 8968): Agent passed 1.0 pipes!, Time: 0.386 epsilon\" 0.0991\n",
            "Episode 187 (Iteration 9005): Agent passed 0.0 pipes!, Time: 0.326 epsilon\" 0.0991\n",
            "Episode 188 (Iteration 9042): Agent passed 0.0 pipes!, Time: 0.325 epsilon\" 0.0991\n",
            "Episode 189 (Iteration 9082): Agent passed 0.0 pipes!, Time: 0.364 epsilon\" 0.0991\n",
            "Episode 190 (Iteration 9155): Agent passed 1.0 pipes!, Time: 0.647 epsilon\" 0.0991\n",
            "Episode 191 (Iteration 9192): Agent passed 0.0 pipes!, Time: 0.331 epsilon\" 0.0991\n",
            "Episode 192 (Iteration 9229): Agent passed 0.0 pipes!, Time: 0.335 epsilon\" 0.0991\n",
            "Episode 193 (Iteration 9266): Agent passed 0.0 pipes!, Time: 0.343 epsilon\" 0.0991\n",
            "Episode 194 (Iteration 9303): Agent passed 0.0 pipes!, Time: 0.352 epsilon\" 0.0991\n",
            "Episode 195 (Iteration 9340): Agent passed 0.0 pipes!, Time: 0.342 epsilon\" 0.0991\n",
            "Episode 196 (Iteration 9416): Agent passed 1.0 pipes!, Time: 0.694 epsilon\" 0.0991\n",
            "Episode 197 (Iteration 9453): Agent passed 0.0 pipes!, Time: 0.344 epsilon\" 0.0991\n",
            "Episode 198 (Iteration 9566): Agent passed 3.0 pipes!, Time: 1.065 epsilon\" 0.0990\n",
            "Weight Saved!\n",
            "Episode 199 (Iteration 9603): Agent passed 0.0 pipes!, Time: 0.385 epsilon\" 0.0990\n",
            "Episode 200 (Iteration 9640): Agent passed 0.0 pipes!, Time: 0.382 epsilon\" 0.0990\n",
            "Episode 201 (Iteration 9688): Agent passed 1.0 pipes!, Time: 0.443 epsilon\" 0.0990\n",
            "Episode 202 (Iteration 9725): Agent passed 0.0 pipes!, Time: 0.352 epsilon\" 0.0990\n",
            "Episode 203 (Iteration 9773): Agent passed 1.0 pipes!, Time: 0.464 epsilon\" 0.0990\n",
            "Episode 204 (Iteration 9813): Agent passed 0.0 pipes!, Time: 0.415 epsilon\" 0.0990\n",
            "Episode 205 (Iteration 9850): Agent passed 0.0 pipes!, Time: 0.333 epsilon\" 0.0990\n",
            "Episode 206 (Iteration 9887): Agent passed 0.0 pipes!, Time: 0.322 epsilon\" 0.0990\n",
            "Episode 207 (Iteration 9924): Agent passed 0.0 pipes!, Time: 0.322 epsilon\" 0.0990\n",
            "Episode 208 (Iteration 9964): Agent passed 0.0 pipes!, Time: 0.343 epsilon\" 0.0990\n",
            "Episode 209 (Iteration 10001): Agent passed 0.0 pipes!, Time: 0.346 epsilon\" 0.0990\n",
            "Episode 210 (Iteration 10050): Agent passed 1.0 pipes!, Time: 0.468 epsilon\" 0.0990\n",
            "Episode 211 (Iteration 10123): Agent passed 1.0 pipes!, Time: 0.649 epsilon\" 0.0990\n",
            "Episode 212 (Iteration 10174): Agent passed 1.0 pipes!, Time: 0.499 epsilon\" 0.0990\n",
            "Episode 213 (Iteration 10283): Agent passed 2.0 pipes!, Time: 1.013 epsilon\" 0.0990\n",
            "Episode 214 (Iteration 10392): Agent passed 2.0 pipes!, Time: 0.959 epsilon\" 0.0990\n",
            "Episode 215 (Iteration 10429): Agent passed 0.0 pipes!, Time: 0.327 epsilon\" 0.0990\n",
            "Episode 216 (Iteration 10466): Agent passed 0.0 pipes!, Time: 0.330 epsilon\" 0.0990\n",
            "Episode 217 (Iteration 10492): Agent passed 0.0 pipes!, Time: 0.242 epsilon\" 0.0990\n",
            "Episode 218 (Iteration 10529): Agent passed 0.0 pipes!, Time: 0.328 epsilon\" 0.0989\n",
            "Episode 219 (Iteration 10602): Agent passed 1.0 pipes!, Time: 0.665 epsilon\" 0.0989\n",
            "Episode 220 (Iteration 10639): Agent passed 0.0 pipes!, Time: 0.345 epsilon\" 0.0989\n",
            "Episode 221 (Iteration 10676): Agent passed 0.0 pipes!, Time: 0.348 epsilon\" 0.0989\n",
            "Episode 222 (Iteration 10713): Agent passed 0.0 pipes!, Time: 0.377 epsilon\" 0.0989\n",
            "Episode 223 (Iteration 10786): Agent passed 1.0 pipes!, Time: 0.694 epsilon\" 0.0989\n",
            "Episode 224 (Iteration 10823): Agent passed 0.0 pipes!, Time: 0.373 epsilon\" 0.0989\n",
            "Episode 225 (Iteration 10860): Agent passed 0.0 pipes!, Time: 0.369 epsilon\" 0.0989\n",
            "Episode 226 (Iteration 10902): Agent passed 1.0 pipes!, Time: 0.424 epsilon\" 0.0989\n",
            "Episode 227 (Iteration 10939): Agent passed 0.0 pipes!, Time: 0.354 epsilon\" 0.0989\n",
            "Episode 228 (Iteration 11012): Agent passed 1.0 pipes!, Time: 0.680 epsilon\" 0.0989\n",
            "Episode 229 (Iteration 11052): Agent passed 0.0 pipes!, Time: 0.369 epsilon\" 0.0989\n",
            "Episode 230 (Iteration 11073): Agent passed 0.0 pipes!, Time: 0.190 epsilon\" 0.0989\n",
            "Episode 231 (Iteration 11110): Agent passed 0.0 pipes!, Time: 0.369 epsilon\" 0.0989\n",
            "Episode 232 (Iteration 11155): Agent passed 1.0 pipes!, Time: 0.413 epsilon\" 0.0989\n",
            "Episode 233 (Iteration 11192): Agent passed 0.0 pipes!, Time: 0.360 epsilon\" 0.0989\n",
            "Episode 234 (Iteration 11233): Agent passed 1.0 pipes!, Time: 0.417 epsilon\" 0.0989\n",
            "Episode 235 (Iteration 11270): Agent passed 0.0 pipes!, Time: 0.351 epsilon\" 0.0989\n",
            "Episode 236 (Iteration 11307): Agent passed 0.0 pipes!, Time: 0.329 epsilon\" 0.0989\n",
            "Episode 237 (Iteration 11344): Agent passed 0.0 pipes!, Time: 0.334 epsilon\" 0.0989\n",
            "Episode 238 (Iteration 11390): Agent passed 1.0 pipes!, Time: 0.415 epsilon\" 0.0989\n",
            "Episode 239 (Iteration 11427): Agent passed 0.0 pipes!, Time: 0.360 epsilon\" 0.0989\n",
            "Episode 240 (Iteration 11464): Agent passed 0.0 pipes!, Time: 0.328 epsilon\" 0.0989\n",
            "Episode 241 (Iteration 11497): Agent passed 0.0 pipes!, Time: 0.296 epsilon\" 0.0989\n",
            "Episode 242 (Iteration 11540): Agent passed 1.0 pipes!, Time: 0.406 epsilon\" 0.0988\n",
            "Episode 243 (Iteration 11613): Agent passed 1.0 pipes!, Time: 0.646 epsilon\" 0.0988\n",
            "Episode 244 (Iteration 11689): Agent passed 1.0 pipes!, Time: 0.694 epsilon\" 0.0988\n",
            "Episode 245 (Iteration 11726): Agent passed 0.0 pipes!, Time: 0.333 epsilon\" 0.0988\n",
            "Episode 246 (Iteration 11768): Agent passed 1.0 pipes!, Time: 0.375 epsilon\" 0.0988\n",
            "Episode 247 (Iteration 11817): Agent passed 1.0 pipes!, Time: 0.426 epsilon\" 0.0988\n",
            "Episode 248 (Iteration 11854): Agent passed 0.0 pipes!, Time: 0.327 epsilon\" 0.0988\n",
            "Episode 249 (Iteration 11891): Agent passed 0.0 pipes!, Time: 0.334 epsilon\" 0.0988\n",
            "Episode 250 (Iteration 11928): Agent passed 0.0 pipes!, Time: 0.342 epsilon\" 0.0988\n",
            "Episode 251 (Iteration 11969): Agent passed 1.0 pipes!, Time: 0.368 epsilon\" 0.0988\n",
            "Episode 252 (Iteration 12006): Agent passed 0.0 pipes!, Time: 0.333 epsilon\" 0.0988\n",
            "Episode 253 (Iteration 12045): Agent passed 0.0 pipes!, Time: 0.352 epsilon\" 0.0988\n",
            "Episode 254 (Iteration 12082): Agent passed 0.0 pipes!, Time: 0.352 epsilon\" 0.0988\n",
            "Episode 255 (Iteration 12128): Agent passed 1.0 pipes!, Time: 0.446 epsilon\" 0.0988\n",
            "Episode 256 (Iteration 12165): Agent passed 0.0 pipes!, Time: 0.337 epsilon\" 0.0988\n",
            "Episode 257 (Iteration 12215): Agent passed 1.0 pipes!, Time: 0.472 epsilon\" 0.0988\n",
            "Episode 258 (Iteration 12335): Agent passed 3.0 pipes!, Time: 1.171 epsilon\" 0.0988\n",
            "Episode 259 (Iteration 12409): Agent passed 1.0 pipes!, Time: 0.688 epsilon\" 0.0988\n",
            "Episode 260 (Iteration 12446): Agent passed 0.0 pipes!, Time: 0.336 epsilon\" 0.0988\n",
            "Episode 261 (Iteration 12491): Agent passed 1.0 pipes!, Time: 0.425 epsilon\" 0.0988\n",
            "Episode 262 (Iteration 12528): Agent passed 0.0 pipes!, Time: 0.367 epsilon\" 0.0987\n",
            "Episode 263 (Iteration 12565): Agent passed 0.0 pipes!, Time: 0.369 epsilon\" 0.0987\n",
            "Episode 264 (Iteration 12602): Agent passed 0.0 pipes!, Time: 0.363 epsilon\" 0.0987\n",
            "Episode 265 (Iteration 12668): Agent passed 1.0 pipes!, Time: 0.613 epsilon\" 0.0987\n",
            "Episode 266 (Iteration 12705): Agent passed 0.0 pipes!, Time: 0.343 epsilon\" 0.0987\n",
            "Episode 267 (Iteration 12742): Agent passed 0.0 pipes!, Time: 0.352 epsilon\" 0.0987\n",
            "Episode 268 (Iteration 12827): Agent passed 2.0 pipes!, Time: 0.774 epsilon\" 0.0987\n",
            "Episode 269 (Iteration 12864): Agent passed 0.0 pipes!, Time: 0.339 epsilon\" 0.0987\n",
            "Episode 270 (Iteration 12901): Agent passed 0.0 pipes!, Time: 0.334 epsilon\" 0.0987\n",
            "Episode 271 (Iteration 12938): Agent passed 0.0 pipes!, Time: 0.322 epsilon\" 0.0987\n",
            "Episode 272 (Iteration 12959): Agent passed 0.0 pipes!, Time: 0.184 epsilon\" 0.0987\n",
            "Episode 273 (Iteration 12996): Agent passed 0.0 pipes!, Time: 0.337 epsilon\" 0.0987\n",
            "Episode 274 (Iteration 13033): Agent passed 0.0 pipes!, Time: 0.335 epsilon\" 0.0987\n",
            "Episode 275 (Iteration 13085): Agent passed 1.0 pipes!, Time: 0.468 epsilon\" 0.0987\n",
            "Episode 276 (Iteration 13136): Agent passed 1.0 pipes!, Time: 0.443 epsilon\" 0.0987\n",
            "Episode 277 (Iteration 13173): Agent passed 0.0 pipes!, Time: 0.324 epsilon\" 0.0987\n",
            "Episode 278 (Iteration 13210): Agent passed 0.0 pipes!, Time: 0.320 epsilon\" 0.0987\n",
            "Episode 279 (Iteration 13248): Agent passed 0.0 pipes!, Time: 0.334 epsilon\" 0.0987\n",
            "Episode 280 (Iteration 13285): Agent passed 0.0 pipes!, Time: 0.332 epsilon\" 0.0987\n",
            "Episode 281 (Iteration 13322): Agent passed 0.0 pipes!, Time: 0.331 epsilon\" 0.0987\n",
            "Episode 282 (Iteration 13359): Agent passed 0.0 pipes!, Time: 0.335 epsilon\" 0.0987\n",
            "Episode 283 (Iteration 13411): Agent passed 1.0 pipes!, Time: 0.468 epsilon\" 0.0987\n",
            "Episode 284 (Iteration 13477): Agent passed 1.0 pipes!, Time: 0.605 epsilon\" 0.0987\n",
            "Episode 285 (Iteration 13550): Agent passed 1.0 pipes!, Time: 0.658 epsilon\" 0.0986\n",
            "Episode 286 (Iteration 13587): Agent passed 0.0 pipes!, Time: 0.356 epsilon\" 0.0986\n",
            "Episode 287 (Iteration 13624): Agent passed 0.0 pipes!, Time: 0.363 epsilon\" 0.0986\n",
            "Episode 288 (Iteration 13733): Agent passed 2.0 pipes!, Time: 1.012 epsilon\" 0.0986\n",
            "Episode 289 (Iteration 13786): Agent passed 1.0 pipes!, Time: 0.486 epsilon\" 0.0986\n",
            "Episode 290 (Iteration 13827): Agent passed 1.0 pipes!, Time: 0.382 epsilon\" 0.0986\n",
            "Episode 291 (Iteration 13864): Agent passed 0.0 pipes!, Time: 0.343 epsilon\" 0.0986\n",
            "Episode 292 (Iteration 13901): Agent passed 0.0 pipes!, Time: 0.343 epsilon\" 0.0986\n",
            "Episode 293 (Iteration 13974): Agent passed 1.0 pipes!, Time: 0.699 epsilon\" 0.0986\n",
            "Episode 294 (Iteration 14011): Agent passed 0.0 pipes!, Time: 0.331 epsilon\" 0.0986\n",
            "Episode 295 (Iteration 14055): Agent passed 1.0 pipes!, Time: 0.434 epsilon\" 0.0986\n",
            "Episode 296 (Iteration 14087): Agent passed 0.0 pipes!, Time: 0.317 epsilon\" 0.0986\n",
            "Episode 297 (Iteration 14127): Agent passed 0.0 pipes!, Time: 0.363 epsilon\" 0.0986\n",
            "Episode 298 (Iteration 14164): Agent passed 0.0 pipes!, Time: 0.337 epsilon\" 0.0986\n",
            "Episode 299 (Iteration 14203): Agent passed 0.0 pipes!, Time: 0.350 epsilon\" 0.0986\n",
            "Episode 300 (Iteration 14245): Agent passed 1.0 pipes!, Time: 0.393 epsilon\" 0.0986\n",
            "Episode 301 (Iteration 14293): Agent passed 1.0 pipes!, Time: 0.479 epsilon\" 0.0986\n",
            "Episode 302 (Iteration 14341): Agent passed 1.0 pipes!, Time: 0.428 epsilon\" 0.0986\n",
            "Episode 303 (Iteration 14378): Agent passed 0.0 pipes!, Time: 0.333 epsilon\" 0.0986\n",
            "Episode 304 (Iteration 14451): Agent passed 1.0 pipes!, Time: 0.650 epsilon\" 0.0986\n",
            "Episode 305 (Iteration 14493): Agent passed 1.0 pipes!, Time: 0.372 epsilon\" 0.0986\n",
            "Episode 306 (Iteration 14536): Agent passed 1.0 pipes!, Time: 0.373 epsilon\" 0.0985\n",
            "Episode 307 (Iteration 14557): Agent passed 0.0 pipes!, Time: 0.190 epsilon\" 0.0985\n",
            "Episode 308 (Iteration 14666): Agent passed 2.0 pipes!, Time: 0.964 epsilon\" 0.0985\n",
            "Episode 309 (Iteration 14703): Agent passed 0.0 pipes!, Time: 0.345 epsilon\" 0.0985\n",
            "Episode 310 (Iteration 14740): Agent passed 0.0 pipes!, Time: 0.357 epsilon\" 0.0985\n",
            "Episode 311 (Iteration 14789): Agent passed 1.0 pipes!, Time: 0.446 epsilon\" 0.0985\n",
            "Episode 312 (Iteration 14838): Agent passed 1.0 pipes!, Time: 0.462 epsilon\" 0.0985\n",
            "Episode 313 (Iteration 14875): Agent passed 0.0 pipes!, Time: 0.342 epsilon\" 0.0985\n",
            "Episode 314 (Iteration 14912): Agent passed 0.0 pipes!, Time: 0.366 epsilon\" 0.0985\n",
            "Episode 315 (Iteration 14954): Agent passed 1.0 pipes!, Time: 0.411 epsilon\" 0.0985\n",
            "Episode 316 (Iteration 14991): Agent passed 0.0 pipes!, Time: 0.345 epsilon\" 0.0985\n",
            "Episode 317 (Iteration 15038): Agent passed 1.0 pipes!, Time: 0.448 epsilon\" 0.0985\n",
            "Episode 318 (Iteration 15075): Agent passed 0.0 pipes!, Time: 0.337 epsilon\" 0.0985\n",
            "Episode 319 (Iteration 15112): Agent passed 0.0 pipes!, Time: 0.338 epsilon\" 0.0985\n",
            "Episode 320 (Iteration 15164): Agent passed 1.0 pipes!, Time: 0.494 epsilon\" 0.0985\n",
            "Episode 321 (Iteration 15201): Agent passed 0.0 pipes!, Time: 0.336 epsilon\" 0.0985\n",
            "Episode 322 (Iteration 15222): Agent passed 0.0 pipes!, Time: 0.206 epsilon\" 0.0985\n",
            "Episode 323 (Iteration 15267): Agent passed 1.0 pipes!, Time: 0.430 epsilon\" 0.0985\n",
            "Episode 324 (Iteration 15304): Agent passed 0.0 pipes!, Time: 0.362 epsilon\" 0.0985\n",
            "Episode 325 (Iteration 15413): Agent passed 2.0 pipes!, Time: 1.058 epsilon\" 0.0985\n",
            "Episode 326 (Iteration 15450): Agent passed 0.0 pipes!, Time: 0.380 epsilon\" 0.0985\n",
            "Episode 327 (Iteration 15487): Agent passed 0.0 pipes!, Time: 0.341 epsilon\" 0.0985\n",
            "Episode 328 (Iteration 15560): Agent passed 1.0 pipes!, Time: 0.700 epsilon\" 0.0984\n",
            "Episode 329 (Iteration 15633): Agent passed 1.0 pipes!, Time: 0.654 epsilon\" 0.0984\n",
            "Episode 330 (Iteration 15670): Agent passed 0.0 pipes!, Time: 0.365 epsilon\" 0.0984\n",
            "Episode 331 (Iteration 15708): Agent passed 0.0 pipes!, Time: 0.353 epsilon\" 0.0984\n",
            "Episode 332 (Iteration 15745): Agent passed 0.0 pipes!, Time: 0.321 epsilon\" 0.0984\n",
            "Episode 333 (Iteration 15791): Agent passed 1.0 pipes!, Time: 0.420 epsilon\" 0.0984\n",
            "Episode 334 (Iteration 15864): Agent passed 1.0 pipes!, Time: 0.647 epsilon\" 0.0984\n",
            "Episode 335 (Iteration 15936): Agent passed 1.0 pipes!, Time: 0.646 epsilon\" 0.0984\n",
            "Episode 336 (Iteration 16009): Agent passed 1.0 pipes!, Time: 0.681 epsilon\" 0.0984\n",
            "Episode 337 (Iteration 16047): Agent passed 0.0 pipes!, Time: 0.331 epsilon\" 0.0984\n",
            "Episode 338 (Iteration 16132): Agent passed 2.0 pipes!, Time: 0.801 epsilon\" 0.0984\n",
            "Episode 339 (Iteration 16169): Agent passed 0.0 pipes!, Time: 0.356 epsilon\" 0.0984\n",
            "Episode 340 (Iteration 16206): Agent passed 0.0 pipes!, Time: 0.356 epsilon\" 0.0984\n",
            "Episode 341 (Iteration 16243): Agent passed 0.0 pipes!, Time: 0.330 epsilon\" 0.0984\n",
            "Episode 342 (Iteration 16296): Agent passed 1.0 pipes!, Time: 0.478 epsilon\" 0.0984\n",
            "Episode 343 (Iteration 16343): Agent passed 1.0 pipes!, Time: 0.427 epsilon\" 0.0984\n",
            "Episode 344 (Iteration 16363): Agent passed 0.0 pipes!, Time: 0.169 epsilon\" 0.0984\n",
            "Episode 345 (Iteration 16400): Agent passed 0.0 pipes!, Time: 0.328 epsilon\" 0.0984\n",
            "Episode 346 (Iteration 16447): Agent passed 1.0 pipes!, Time: 0.435 epsilon\" 0.0984\n",
            "Episode 347 (Iteration 16484): Agent passed 0.0 pipes!, Time: 0.332 epsilon\" 0.0984\n",
            "Episode 348 (Iteration 16524): Agent passed 0.0 pipes!, Time: 0.382 epsilon\" 0.0983\n",
            "Episode 349 (Iteration 16633): Agent passed 2.0 pipes!, Time: 1.035 epsilon\" 0.0983\n",
            "Episode 350 (Iteration 16670): Agent passed 0.0 pipes!, Time: 0.339 epsilon\" 0.0983\n",
            "Episode 351 (Iteration 16705): Agent passed 0.0 pipes!, Time: 0.311 epsilon\" 0.0983\n",
            "Episode 352 (Iteration 16742): Agent passed 0.0 pipes!, Time: 0.369 epsilon\" 0.0983\n",
            "Episode 353 (Iteration 16781): Agent passed 0.0 pipes!, Time: 0.376 epsilon\" 0.0983\n",
            "Episode 354 (Iteration 16805): Agent passed 0.0 pipes!, Time: 0.223 epsilon\" 0.0983\n",
            "Episode 355 (Iteration 16842): Agent passed 0.0 pipes!, Time: 0.361 epsilon\" 0.0983\n",
            "Episode 356 (Iteration 16879): Agent passed 0.0 pipes!, Time: 0.359 epsilon\" 0.0983\n",
            "Episode 357 (Iteration 16952): Agent passed 1.0 pipes!, Time: 0.688 epsilon\" 0.0983\n",
            "Episode 358 (Iteration 17025): Agent passed 1.0 pipes!, Time: 0.684 epsilon\" 0.0983\n",
            "Episode 359 (Iteration 17062): Agent passed 0.0 pipes!, Time: 0.335 epsilon\" 0.0983\n",
            "Episode 360 (Iteration 17135): Agent passed 1.0 pipes!, Time: 0.646 epsilon\" 0.0983\n",
            "Episode 361 (Iteration 17212): Agent passed 2.0 pipes!, Time: 0.692 epsilon\" 0.0983\n",
            "Episode 362 (Iteration 17249): Agent passed 0.0 pipes!, Time: 0.329 epsilon\" 0.0983\n",
            "Episode 363 (Iteration 17289): Agent passed 0.0 pipes!, Time: 0.381 epsilon\" 0.0983\n",
            "Episode 364 (Iteration 17326): Agent passed 0.0 pipes!, Time: 0.328 epsilon\" 0.0983\n",
            "Episode 365 (Iteration 17363): Agent passed 0.0 pipes!, Time: 0.320 epsilon\" 0.0983\n",
            "Episode 366 (Iteration 17400): Agent passed 0.0 pipes!, Time: 0.328 epsilon\" 0.0983\n",
            "Episode 367 (Iteration 17437): Agent passed 0.0 pipes!, Time: 0.327 epsilon\" 0.0983\n",
            "Episode 368 (Iteration 17475): Agent passed 0.0 pipes!, Time: 0.334 epsilon\" 0.0983\n",
            "Episode 369 (Iteration 17548): Agent passed 1.0 pipes!, Time: 0.660 epsilon\" 0.0982\n",
            "Episode 370 (Iteration 17585): Agent passed 0.0 pipes!, Time: 0.329 epsilon\" 0.0982\n",
            "Episode 371 (Iteration 17651): Agent passed 1.0 pipes!, Time: 0.586 epsilon\" 0.0982\n",
            "Episode 372 (Iteration 17724): Agent passed 1.0 pipes!, Time: 0.644 epsilon\" 0.0982\n",
            "Episode 373 (Iteration 17788): Agent passed 1.0 pipes!, Time: 0.567 epsilon\" 0.0982\n",
            "Episode 374 (Iteration 17825): Agent passed 0.0 pipes!, Time: 0.325 epsilon\" 0.0982\n",
            "Episode 375 (Iteration 17862): Agent passed 0.0 pipes!, Time: 0.327 epsilon\" 0.0982\n",
            "Episode 376 (Iteration 17901): Agent passed 0.0 pipes!, Time: 0.384 epsilon\" 0.0982\n",
            "Episode 377 (Iteration 17938): Agent passed 0.0 pipes!, Time: 0.352 epsilon\" 0.0982\n",
            "Episode 378 (Iteration 17975): Agent passed 0.0 pipes!, Time: 0.366 epsilon\" 0.0982\n",
            "Episode 379 (Iteration 18012): Agent passed 0.0 pipes!, Time: 0.332 epsilon\" 0.0982\n",
            "Episode 380 (Iteration 18049): Agent passed 0.0 pipes!, Time: 0.334 epsilon\" 0.0982\n",
            "Episode 381 (Iteration 18086): Agent passed 0.0 pipes!, Time: 0.356 epsilon\" 0.0982\n",
            "Episode 382 (Iteration 18123): Agent passed 0.0 pipes!, Time: 0.376 epsilon\" 0.0982\n",
            "Episode 383 (Iteration 18160): Agent passed 0.0 pipes!, Time: 0.349 epsilon\" 0.0982\n",
            "Episode 384 (Iteration 18210): Agent passed 1.0 pipes!, Time: 0.492 epsilon\" 0.0982\n",
            "Episode 385 (Iteration 18247): Agent passed 0.0 pipes!, Time: 0.350 epsilon\" 0.0982\n",
            "Episode 386 (Iteration 18284): Agent passed 0.0 pipes!, Time: 0.360 epsilon\" 0.0982\n",
            "Episode 387 (Iteration 18321): Agent passed 0.0 pipes!, Time: 0.348 epsilon\" 0.0982\n",
            "Episode 388 (Iteration 18358): Agent passed 0.0 pipes!, Time: 0.336 epsilon\" 0.0982\n",
            "Episode 389 (Iteration 18395): Agent passed 0.0 pipes!, Time: 0.352 epsilon\" 0.0982\n",
            "Episode 390 (Iteration 18465): Agent passed 1.0 pipes!, Time: 0.692 epsilon\" 0.0982\n",
            "Episode 391 (Iteration 18538): Agent passed 1.0 pipes!, Time: 0.656 epsilon\" 0.0981\n",
            "Episode 392 (Iteration 18591): Agent passed 1.0 pipes!, Time: 0.476 epsilon\" 0.0981\n",
            "Episode 393 (Iteration 18664): Agent passed 1.0 pipes!, Time: 0.658 epsilon\" 0.0981\n",
            "Episode 394 (Iteration 18701): Agent passed 0.0 pipes!, Time: 0.344 epsilon\" 0.0981\n",
            "Episode 395 (Iteration 18774): Agent passed 1.0 pipes!, Time: 0.654 epsilon\" 0.0981\n",
            "Episode 396 (Iteration 18812): Agent passed 0.0 pipes!, Time: 0.336 epsilon\" 0.0981\n",
            "Episode 397 (Iteration 18838): Agent passed 0.0 pipes!, Time: 0.233 epsilon\" 0.0981\n",
            "Episode 398 (Iteration 18875): Agent passed 0.0 pipes!, Time: 0.323 epsilon\" 0.0981\n",
            "Episode 399 (Iteration 18924): Agent passed 1.0 pipes!, Time: 0.458 epsilon\" 0.0981\n",
            "Episode 400 (Iteration 18997): Agent passed 1.0 pipes!, Time: 0.696 epsilon\" 0.0981\n",
            "Episode 401 (Iteration 19034): Agent passed 0.0 pipes!, Time: 0.337 epsilon\" 0.0981\n",
            "Episode 402 (Iteration 19087): Agent passed 1.0 pipes!, Time: 0.482 epsilon\" 0.0981\n",
            "Episode 403 (Iteration 19108): Agent passed 0.0 pipes!, Time: 0.202 epsilon\" 0.0981\n",
            "Episode 404 (Iteration 19192): Agent passed 2.0 pipes!, Time: 0.803 epsilon\" 0.0981\n",
            "Episode 405 (Iteration 19236): Agent passed 1.0 pipes!, Time: 0.407 epsilon\" 0.0981\n",
            "Episode 406 (Iteration 19273): Agent passed 0.0 pipes!, Time: 0.352 epsilon\" 0.0981\n",
            "Episode 407 (Iteration 19318): Agent passed 1.0 pipes!, Time: 0.410 epsilon\" 0.0981\n",
            "Episode 408 (Iteration 19355): Agent passed 0.0 pipes!, Time: 0.349 epsilon\" 0.0981\n",
            "Episode 409 (Iteration 19392): Agent passed 0.0 pipes!, Time: 0.341 epsilon\" 0.0981\n",
            "Episode 410 (Iteration 19429): Agent passed 0.0 pipes!, Time: 0.338 epsilon\" 0.0981\n",
            "Episode 411 (Iteration 19502): Agent passed 1.0 pipes!, Time: 0.663 epsilon\" 0.0981\n",
            "Episode 412 (Iteration 19539): Agent passed 0.0 pipes!, Time: 0.344 epsilon\" 0.0980\n",
            "Episode 413 (Iteration 19573): Agent passed 0.0 pipes!, Time: 0.313 epsilon\" 0.0980\n",
            "Episode 414 (Iteration 19623): Agent passed 1.0 pipes!, Time: 0.467 epsilon\" 0.0980\n",
            "Episode 415 (Iteration 19660): Agent passed 0.0 pipes!, Time: 0.341 epsilon\" 0.0980\n",
            "Episode 416 (Iteration 19702): Agent passed 1.0 pipes!, Time: 0.396 epsilon\" 0.0980\n",
            "Episode 417 (Iteration 19739): Agent passed 0.0 pipes!, Time: 0.358 epsilon\" 0.0980\n",
            "Episode 418 (Iteration 19788): Agent passed 1.0 pipes!, Time: 0.484 epsilon\" 0.0980\n",
            "Episode 419 (Iteration 19825): Agent passed 0.0 pipes!, Time: 0.360 epsilon\" 0.0980\n",
            "Episode 420 (Iteration 19862): Agent passed 0.0 pipes!, Time: 0.344 epsilon\" 0.0980\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-3ecd8de6336f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mimage_data_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_torch_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mstate_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_data_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/Colab Notebooks/Kaggle/project_4_RL/RL_Challenge/game.py\u001b[0m in \u001b[0;36mget_torch_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_torch_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetScreenRGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/Colab Notebooks/Kaggle/project_4_RL/RL_Challenge/ple/ple.pyc\u001b[0m in \u001b[0;36mgetScreenRGB\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/Colab Notebooks/Kaggle/project_4_RL/RL_Challenge/ple/pygamewrapper.pyc\u001b[0m in \u001b[0;36mgetScreenRGB\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pygame/surfarray.py\u001b[0m in \u001b[0;36marray3d\u001b[0;34m(surface)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0msurface_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기존 코드"
      ],
      "metadata": {
        "id": "4_PeL9LW9i_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "from glob import glob\n",
        "from collections import deque\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "\n",
        "from game import Game\n",
        "from utils import init_weights\n",
        "from munch import Munch\n",
        "\n",
        "def train(args):\n",
        "    model = DQN()\n",
        "    if args.use_pretrained:\n",
        "        model = torch.load(\n",
        "            sorted(glob(os.path.join('ckpt', args.tag, '*.pth')))[-1]\n",
        "        )\n",
        "    else:\n",
        "        os.makedirs(os.path.join('ckpt', args.tag), exist_ok = True)\n",
        "        model.apply(init_weights)\n",
        "    model = model.cuda()\n",
        "    start = time.time()\n",
        "\n",
        "    episode = 0\n",
        "    iteration = 0\n",
        "    epsilon = args.epsilon\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "    # instantiate game\n",
        "    game = Game(game=args.game)\n",
        "    high_total_reward = 0\n",
        "\n",
        "    # initialize replay memory\n",
        "    \"\"\"\n",
        "    TO DO\n",
        "\n",
        "    D =\n",
        "    \"\"\"\n",
        "\n",
        "    elapsed_time = 0\n",
        "    action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "    total_reward = game.reward\n",
        "    terminal = game.game_over()\n",
        "\n",
        "    image_data = game.get_torch_image().cuda()\n",
        "    state = image_data.unsqueeze(0)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    while iteration < args.iteration:\n",
        "        output = model(state)[0]\n",
        "        action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "\n",
        "        # epsilon greedy exploration\n",
        "        random_action = False\n",
        "        \"\"\"\n",
        "        TO DO\n",
        "\n",
        "        random_action =\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick action --> random or index of maximum q value\n",
        "        action_index = 0\n",
        "        \"\"\"\n",
        "        TO DO\n",
        "\n",
        "        action_index =\n",
        "        \"\"\"\n",
        "\n",
        "        action[action_index] = 1\n",
        "\n",
        "        elapsed_time = time.time() - start\n",
        "\n",
        "        # get next state and reward\n",
        "        reward = game.act(action_index)\n",
        "        terminal = game.game_over()\n",
        "        image_data_1 = game.get_torch_image().cuda()\n",
        "\n",
        "        state_1 = image_data_1.unsqueeze(0)\n",
        "        action = action.unsqueeze(0).cuda()\n",
        "        reward = torch.from_numpy(np.array([reward], dtype=np.float32)).unsqueeze(0).cuda()\n",
        "\n",
        "        # save transition to replay memory\n",
        "        \"\"\"\n",
        "        TO DO\n",
        "        \"\"\"\n",
        "\n",
        "        # if replay memory is full, remove the oldest transition\n",
        "        \"\"\"\n",
        "        TO DO\n",
        "        \"\"\"\n",
        "\n",
        "        # sample random minibatch\n",
        "        \"\"\"\n",
        "        TO DO\n",
        "        \"\"\"\n",
        "\n",
        "        # get output for the next state\n",
        "        output_1 = model(state_1)\n",
        "\n",
        "        y = reward if terminal else reward + args.gamma * torch.max(output_1)\n",
        "\n",
        "        # calculate with target network\n",
        "        q_value = torch.sum(model(state) * action, dim=1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y = y.detach()\n",
        "        loss = criterion(q_value, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        state = state_1\n",
        "        iteration += 1\n",
        "        total_reward += game.reward\n",
        "\n",
        "        args.writer.add_scalar('Train/loss', loss, iteration)\n",
        "\n",
        "        if terminal:\n",
        "            args.writer.add_scalar('Episode/elapsed_time', elapsed_time, episode)\n",
        "            args.writer.add_scalar('Episode/episode', episode, episode)\n",
        "            args.writer.add_scalar('Episode/total_reward', total_reward, episode)\n",
        "            total_reward = 0\n",
        "            game.reset_game()\n",
        "            episode += 1\n",
        "            start = time.time()\n",
        "            print('Episode {} (Iteration {}): Agent passed {} pipes!, Time: {:.3f}'.format(episode, iteration, total_reward, elapsed_time))\n",
        "            if total_reward > high_total_reward:\n",
        "                print('Weight Saved!')\n",
        "                high_total_reward = total_reward\n",
        "                torch.save(model,\n",
        "                           os.path.join('ckpt', args.tag, 'E{:07d}_S{:03d}.pth'.format(episode, int(total_reward)))\n",
        "                           )\n",
        "    print(\"Saving final model\")\n",
        "    torch.save(model,\n",
        "               os.path.join('ckpt', args.tag, 'E_{:07d}_S{:03d}.pth'.format(episode, int(high_total_reward)))\n",
        "               )"
      ],
      "metadata": {
        "id": "5-8NHrQgX1qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from munch import Munch\n",
        "#parser = argparse.ArgumentParser(description='Deep Q Learning')\n",
        "# Simple parser\n",
        "args = {\n",
        "    \"game\": \"flappy\",\n",
        "    \"gamma\": 0.99,\n",
        "    \"epsilon\": 0.02,\n",
        "    \"iteration\": 1000000,\n",
        "    \"lr\": 1e-4,\n",
        "    \"use_pretrained\": False,\n",
        "    \"tag\": \"dqn\",\n",
        "    \"writer\": \"writer\"\n",
        "}\n",
        "args = Munch(args)\n",
        "\n",
        "args.writer = SummaryWriter(os.path.join('ckpt', args.tag))\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "print('GPU Enabled: {}'.format(torch.cuda.is_available()))\n",
        "\n",
        "train(args)\n"
      ],
      "metadata": {
        "id": "nZxWPpsCX7Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=ckpt/dqn"
      ],
      "metadata": {
        "id": "KVY8Ylk86fV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "QabXdcmgqmwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import argparse\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "\n",
        "from game import Game\n",
        "from utils import Recorder\n",
        "\n",
        "def test(args):\n",
        "    model = torch.load(\n",
        "        sorted(glob(os.path.join('ckpt', args.tag, '*.pth')))[-1],\n",
        "        map_location='cpu'\n",
        "    ).eval()\n",
        "    print('Loaded model: {}'.format(sorted(glob(os.path.join('ckpt', args.tag, '*.pth')))[-1]))\n",
        "    # initialize video writer\n",
        "    video_filename = 'output_{}.avi'.format(args.tag)\n",
        "\n",
        "    dict_screen_shape = {\n",
        "        \"flappy\":(288, 512),\n",
        "    }\n",
        "    out = Recorder(video_filename=video_filename, fps=30,\n",
        "                   width=dict_screen_shape[args.game][0],\n",
        "                   height=dict_screen_shape[args.game][1])\n",
        "    total_reward_list = []\n",
        "    time_list = []\n",
        "\n",
        "    rewards = {\n",
        "        \"positive\": 1, # when the plasyer pass the pipe\n",
        "        \"tick\": 0, # at every tick\n",
        "        \"loss\": 0, # when died\n",
        "    }\n",
        "    game = Game(seed=args.seed, game=args.game, rewards=rewards)\n",
        "    for trials in range(10):\n",
        "\n",
        "        elapsed_Time = 0\n",
        "        action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "        terminal = game.game_over()\n",
        "        start = time.time()\n",
        "        total_reward = 0\n",
        "\n",
        "        image_data = game.get_torch_image()\n",
        "        state = image_data.unsqueeze(0)\n",
        "        while not terminal:\n",
        "            output = model(state)[0]\n",
        "            action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "            action_index = torch.argmax(output)\n",
        "            total_reward += game.act(action_index)\n",
        "            terminal = game.game_over()\n",
        "            image_data_1 = game.get_torch_image()\n",
        "            state = image_data_1.unsqueeze(0)\n",
        "\n",
        "            out.write(game.get_image())\n",
        "\n",
        "        game.reset_game()\n",
        "        total_reward_list.append(total_reward)\n",
        "        time_list.append(time.time()-start)\n",
        "        print('Game Ended!')\n",
        "        print('Total reward: {} !'.format(total_reward))\n",
        "\n",
        "    # Add summary\n",
        "    out.write_score(sum(total_reward_list), sum(time_list))\n",
        "    out.save()\n",
        "    print('Cumulated Total Reward: {}'.format(sum(total_reward_list)))\n",
        "    print('Total Run Time: {:.3f}'.format(sum(time_list)))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='Deep Q Learning')\n",
        "    parser.add_argument('--seed', default=42, type=int,\n",
        "                        help='Random seed')\n",
        "    parser.add_argument('--game', default='flappy', type=str,\n",
        "                        help='{flappy}')\n",
        "    parser.add_argument('--tag', default=\"dqn\", type=str,\n",
        "                        help='name to save')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    test(args)"
      ],
      "metadata": {
        "id": "FTb8BqhoqlhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eHhExncNqlc4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}